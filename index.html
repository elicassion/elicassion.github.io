<!DOCTYPE html>
<html lang="en">
<head>
<!--    <link rel="stylesheet" href="https://latex.now.sh/style.css">-->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,400,900">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Google+Sans:300,400,700">
    <!-- ||Noto+Sans|Castoro"> -->
    <link rel="stylesheet" href="latex.css">
    <meta charset="UTF-8">
    <base target="_blank">
    <title>Jinghuan Shang - Stony Brook University</title>
</head>
<body>
    <!-- <header>
        <h1 class="">尚靖桓 Jinghuan Shang</h1>
    </header> -->
    <div class="intro">
        <table class="noborder">
            <tr >
                <td class="noborder">
                    <div class="portrait" style="background-image: url('portrait.jpg');"> </div>
                </td>
                <td class="noborder">   </td>
                <td class="noborder">   </td>
                <td class="noborder">
                    <div>
                        <h2>尚靖桓 Jinghuan Shang</h2>
                        <p>I'm a Ph.D. candidate in the <a href="https://www.cs.stonybrook.edu" >Department of Computer Science</a> at <a href="https://www.stonybrook.edu" > Stony Brook University</a>, working with <a href="http://michaelryoo.com/" >Prof. Michael Ryoo</a>, as a part of <a href="https://www3.cs.stonybrook.edu/~cvl/people.html" >CV Lab</a> at Stony Brook.
                            I received my Bachelor's degree from <a href="http://english.seiee.sjtu.edu.cn/english/info/8338.htm" >IEEE Honored Class</a> at Shanghai Jiao Tong University (SJTU) in 2018, with honor from Shanghai.
                        </p>
                        <p>
                            Research interest: <b>Representation Learning</b>, <b>Robotics</b>, and <b>Computer Vision</b>.
                            Specifically, I find good visual representations for robots to perform visual tasks under reinforcement learning and imitation learning settings.
                        </p>
                        <p> <a href="cv.pdf" >[CV]</a><a href="https://github.com/elicassion" >[GitHub]</a> Email: jishang [at] cs &dot& stony brook %dot% edu</p>
                    </div>
                </td>
            </tr>
        </table>
    </div>
    <div class="news">
        <h2>News</h2>
        <p>2022/09 - <a href="./3dtrl/3dtrl.html" >3DTRL</a> and <a href="https://arxiv.org/abs/2206.05266">Study on SSL+RL</a> are accepted to <b>NeurIPS</b> 2022.
        <p>2022/09 - <a href="./triton/triton.html">TRITON</a> for robot sim2real is accepted to <b>CoRL</b> 2022.</p>
        <p>2022/09 - StARformer for real robot is accepted to <b>TPAMI</b>. A cute ground mobility robot is able to continuously follow me purely by visual inputs.</p>
        <p>2022/08 - Started a research internship at <a href="https://motional.com/publications">Motional</a>.</p>
        <p>2022/07 - <a href="https://arxiv.org/abs/2110.06206" ><b>StAR</b>former</a> is accepted to <b>ECCV</b> 2022. Local representations benefit long-term sequence modeling in vision-based RL.</p>
        <!-- <p>2022/06 - Robot Sim to Reeeaaaal? Check <a href="./triton/triton.html">TRITON</a> using neural neural texture and differentiable rendering!</p> -->
        <p>2022/06 - Introducing <a href="./3dtrl/3dtrl.html" >3D Token Representation Layer</a>, a plug-and-play module for Transformer to learn viewpoint-agnostic representations.</p>
        <p>2021/06 - <a href="https://arxiv.org/abs/2206.05266" >Does Self-supervised Learning Really Improve Reinforcement Learning from Pixels?</a> </p>
        <!-- <p>2021/10 - Introducing <a href="https://arxiv.org/abs/2110.06206" ><b>StAR</b>former</a> for Reinforcement Learning and Imitation Learning! It learns <b>St</b>ate-<b>A</b>ction-<b>R</b>eward-representations to improve long-term trajectory modeling, and archive better benchmark performance.</p> -->
        <!-- <p>2021/09 - Presented the Third-Person Imitation Learning paper at IROS 2021.</p> -->
        <p>2021/06 - Our paper on <a href="https://arxiv.org/abs/2108.01069" >Third-Person Imitation Learning</a> is accepted to IROS 2021. </p>
    </div>
    <div class="publication">
        <h2>Publications and Preprints</h2>
        <table class="noborder">
            <tr>
                <td class="noborder">
                    <div class="teaser">
                        <table class="noborder">
                            <tr>
                                <td class="noborder" width="50%">
                                    <img src="3dtrl/3d_patches/original/06500.png" style="width: 100%">
                                </td>
                                <td class="noborder" width="50%">
                                    <img src="3dtrl/3d_patches/gif/06500.gif" style="width: 100%">
                                </td>
                            </tr>
                        </table>
                    </div>
                </td>

                <td class="noborder">
                    <span class="title">Learning Viewpoint-Agnostic Visual Representations by Recovering Tokens in 3D Space</span>
                    <br/>
                    <u><b>Jinghuan Shang</b></u>, <a class="author" href="https://srijandas07.github.io">Srijan Das</a>, and <a class="author" href="http:michaelryoo.com">Michael S. Ryoo</a>
                    <br/>
                    <b>NeurIPS</b> 2022
                    <br/>
                    <a href="./3dtrl/3dtrl.html" >[Project Page]</a>
                    <a href="https://github.com/elicassion/3DTRL" >[Code]</a>
                    <a href="https://arxiv.org/abs/2206.11895" >[arXiv]</a>
                </td>
            </tr>
            <tr>
                <td class="noborder">
                    <div class="teaser" style="background-image: url('sslrl.png')"></div>
                </td>
                <td class="noborder">
                    <span class="title">Does Self-supervised Learning Really Improve Reinforcement Learning from Pixels?</span>
                    <br/>
                    <a class="author" href="https://xxli.me">Xiang Li</a>, <u><b>Jinghuan Shang</b></u>, <a class="author" href="https://srijandas07.github.io">Srijan Das</a>, and <a class="author" href="http://michaelryoo.com">Michael S. Ryoo</a>
                    <br/>
                    <b>NeurIPS</b> 2022
                    <br/>
                    <a href="https://arxiv.org/abs/2206.05266" >[arXiv]</a>
                </td>
            </tr>
            <tr>
                <td class="noborder">
                    <div class="teaser" style="background-image: url('triton/just_robot.gif')"></div>
                </td>
                <td class="noborder">
                    <span class="title"> Neural Neural Textures Make Sim2Real Consistent </span>
                    <br/>
                    <span class="author">Ryan Burgert</span>, <u><b>Jinghuan Shang</b></u>, <a class="author" href="https://xxli.me" >Xiang Li</a>, and <a class="author" href="http://michaelryoo.com" >Michael S. Ryoo</a>
                    <br/>
                    <b>CoRL</b> 2022
                    <br/>
                    <a href="https://tritonpaper.github.io" >[Project Page]</a>
                    [Code -- Coming Soon]
                    <a href="https://arxiv.org/abs/2206.13500" >[arXiv]</a>
                </td>
            </tr>
            <tr>
                <td class="noborder">
                    <div class="teaser" style="background-image: url('starformer/star_hf_clip_star.gif')"></div>
                </td>
                <td class="noborder">
                    <span class="title">StARformer: Transformer with State-Action-Reward Representations for Robot Learning</span>
                    <br/>
                    <u><b>Jinghuan Shang</u></b>, <a class="author" href="https://xxli.me" >Xiang Li</a>, <a class="author" href="https://www3.cs.stonybrook.edu/~kkahatapitiy">Kumara Kahatapitiya</a>, <a class="author" href="https://sites.google.com/site/yucheollee/">Yu-Cheol Lee<a>, <a class="author" href="http://michaelryoo.com" >Michael S. Ryoo</a>
                    <br/>
                    <b>IEEE TPAMI</b>, Special Issue on Transformer Models in Vision, 2022
                    <br/>
                    <a href="./starformer/Starformer_TPAMI_final.pdf">[PDF]</a>
                </td>
            </tr>
            <tr>
                <td class="noborder">
                    <div class="teaser" style="background-image: url('starformer.png')"></div>
                </td>
                <td class="noborder">
                    <span class="title">StARformer: Transformer with State-Action-Reward Representations for Visual Reinforcement Learning</span>
                    <br/>
                    <u><b>Jinghuan Shang</b></u>, <a class="author" href="https://www3.cs.stonybrook.edu/~kkahatapitiy">Kumara Kahatapitiya</a>, <a class="author" href="https://xxli.me">Xiang Li</a>, and <a class="author" href="http://michaelryoo.com"> Michael S. Ryoo</a>
                    <br/>
                    <b>ECCV</b> 2022
                    <br/>
                    <a href="https://arxiv.org/abs/2110.06206" >[arXiv]</a>
                    <a href="https://github.com/elicassion/StARformer" >[Code]</a>
                    <a href="https://drive.google.com/file/d/1OBZi24dDzueteNTJIjr-pISoDaSKMli4/view?usp=sharing">[Video]</a>
                    <a href="./starformer/4447.pdf">[Poster]</a>
                </td>
            </tr>
            <tr>
                <td class="noborder">
                    <div class="teaser" style="background-image: url('iros2021.gif');"></div>
                </td>
                <td class="noborder">
                    <span class="title"> Self-Supervised Disentangled Representation Learning for Third-Person Imitation Learning </span>
                    <br/>
                    <u><b>Jinghuan Shang</b></u> and <a class="author" href="http://michaelryoo.com">Michael S. Ryoo</a>
                    <br/>
                    <b>IROS</b> 2021
                    <br/>
                    <a href="https://arxiv.org/abs/2108.01069" >[arXiv]</a>
                    <a href="https://drive.google.com/file/d/1YQtkF4wyo9s1sMk59y6bKBgspqw2-fEs/view?usp=sharing" >[Talk]</a>
                    <a href="https://drive.google.com/file/d/1cb5PbWPtd20GSjBWEy8xeUGjw6xwJwvt/view?usp=sharing" >[Digest Slide]</a>
                </td>
            </tr>
        </table>
    </div>
    <div>
        <h2>Honors and Awards</h2>

        <table class="noborder">
            <tr><td class="noborder">2022/10</td><td class="noborder">- NeurIPS 2022 Scholar Award</td>
            <tr><td class="noborder">2018/08</td><td class="noborder">- Merit Scholarship from the Department of Computer Science at Stony Brook University</td></tr>
            <tr><td class="noborder">2018/06</td><td class="noborder">- Outstanding graduate among all graduates from universities in Shanghai</td></tr>
            <tr><td class="noborder">2016</td><td class="noborder">- 1st Prize in Shanghai Division of China Undergraduate Mathematical Contest in Modeling (CUMCM)</td></tr>
            <tr><td class="noborder">2015-2017</td><td class="noborder">- 3 times of Academic Excellence Scholarship at Shanghai Jiao Tong University</td></tr>
        </table>
    </div>
    <div>
        <h2>Fun</h2>
        <p>I love <a href="./cooking/cooking.html">cooking</a>. </p>
        <p>I solve some algorithm problems in my spare time. Luckily got <b>Top 10</b> in <a href="https://www.hackerrank.com/contests/sbu-selection-2020/leaderboard" >2020 SBU ICPC Slection Contest</a>. Here is my <a href="https://leetcode.com/etoss/" >[Leetcode]</a>.</p>
    </div>

    <p class="footnotes">Last modified 2022/09. Style Credit: <a href="https://github.com/vincentdoerig/latex-css" >latex.css</a></p>
</body>
</html>